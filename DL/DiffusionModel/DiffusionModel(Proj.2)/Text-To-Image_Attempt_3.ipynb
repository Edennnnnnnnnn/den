{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from torch import Tensor, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm, trange\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbeddings(torch.nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class TemporalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, dim_emb, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(dim_emb, dim_out)\n",
    "        self.temb = SinusoidalPositionEmbeddings(dim_emb)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        temb = self.temb(time)\n",
    "        emb = self.linear(temb)\n",
    "        emb = emb[:, :, None, None]\n",
    "        out = x + emb\n",
    "        return out\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        base_channel = 16\n",
    "\n",
    "        factor = 2 if bilinear else 1\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, base_channel))\n",
    "        self.down1 = (Down(base_channel, base_channel * 2))\n",
    "        self.down2 = (Down(base_channel * 2, base_channel * 4 // factor))\n",
    "        self.up1 = (Up(base_channel * 4, base_channel * 2 // factor, bilinear))\n",
    "        self.up2 = (Up(base_channel * 2, base_channel, bilinear))\n",
    "        self.outc = (OutConv(base_channel, n_classes))\n",
    "\n",
    "        self.embed1 = TemporalEmbedding(1024, n_channels)\n",
    "        self.embed2 = TemporalEmbedding(1024, base_channel)\n",
    "        self.embed3 = TemporalEmbedding(1024, base_channel * 2)\n",
    "        self.embed4 = TemporalEmbedding(1024, base_channel * 4)\n",
    "        self.embed5 = TemporalEmbedding(1024, base_channel * 2)\n",
    "        self.embed6 = TemporalEmbedding(1024, base_channel)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.embed1(x, t)\n",
    "        x1 = self.inc(x)\n",
    "\n",
    "        x1 = self.embed2(x1, t)\n",
    "        x2 = self.down1(x1)\n",
    "\n",
    "        x2 = self.embed3(x2, t)\n",
    "        x3 = self.down2(x2)\n",
    "\n",
    "        x3 = self.embed4(x3, t)\n",
    "        x = self.up1(x3, x2)\n",
    "\n",
    "        x = self.embed5(x, t)\n",
    "        x = self.up2(x, x1)\n",
    "\n",
    "        x = self.embed6(x, t)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class UNetPlus(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNetPlus, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        base_channel = 32\n",
    "        factor = 2 if bilinear else 1\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, base_channel)\n",
    "        self.down1 = Down(base_channel, base_channel * 2)\n",
    "        self.down2 = Down(base_channel * 2, base_channel * 4)\n",
    "        self.down3 = Down(base_channel * 4, base_channel * 8)\n",
    "        self.down4 = Down(base_channel * 8, base_channel * 16 // factor)\n",
    "\n",
    "        self.up1 = Up(base_channel * 16, base_channel * 8 // factor, bilinear)\n",
    "        self.up2 = Up(base_channel * 8, base_channel * 4 // factor, bilinear)\n",
    "        self.up3 = Up(base_channel * 4, base_channel * 2 // factor, bilinear)\n",
    "        self.up4 = Up(base_channel * 2, base_channel, bilinear)\n",
    "\n",
    "        self.outc = OutConv(base_channel, n_classes)\n",
    "\n",
    "        self.embed1 = TemporalEmbedding(1024, 1)\n",
    "        self.embed2 = TemporalEmbedding(1024, base_channel)\n",
    "        self.embed3 = TemporalEmbedding(1024, base_channel * 2)\n",
    "        self.embed4 = TemporalEmbedding(1024, base_channel * 4)\n",
    "        self.embed5 = TemporalEmbedding(1024, base_channel * 8)\n",
    "        self.embed6 = TemporalEmbedding(1024, base_channel * 16)\n",
    "        self.embed7 = TemporalEmbedding(1024, base_channel * 8)\n",
    "        self.embed8 = TemporalEmbedding(1024, base_channel * 4)\n",
    "        self.embed9 = TemporalEmbedding(1024, base_channel * 2)\n",
    "        self.embed10 = TemporalEmbedding(1024, base_channel)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.embed1(x, t)\n",
    "        x1 = self.inc(x)\n",
    "\n",
    "        x1 = self.embed2(x1, t)\n",
    "        x2 = self.down1(x1)\n",
    "\n",
    "        x2 = self.embed3(x2, t)\n",
    "        x3 = self.down2(x2)\n",
    "\n",
    "        x3 = self.embed4(x3, t)\n",
    "        x4 = self.down3(x3)\n",
    "\n",
    "        x4 = self.embed5(x4, t)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x5 = self.embed6(x5, t)\n",
    "        x = self.up1(x5, x4)\n",
    "\n",
    "        x = self.embed7(x, t)\n",
    "        x = self.up2(x, x3)\n",
    "\n",
    "        x = self.embed8(x, t)\n",
    "        x = self.up3(x, x2)\n",
    "\n",
    "        x = self.embed9(x, t)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        x = self.embed10(x, t)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DiffusionProcess:\n",
    "    def __init__(self, device, batchSize=64, timeSteps=999, betaMode=\"Cosine\"):\n",
    "        self.batchSize = batchSize\n",
    "        self.timeSteps = timeSteps\n",
    "        self.betaMode = betaMode\n",
    "        self.betas = None\n",
    "        self.device = device\n",
    "        self._initHyperparams()\n",
    "\n",
    "    def _initHyperparams(self):\n",
    "        if self.betaMode == \"Quadratic\":\n",
    "            self.betas = self._getQuadraticBetas(self.device, self.timeSteps)\n",
    "        elif self.betaMode == \"Sigmoid\":\n",
    "            self.betas = self._getSigmoidBetas(self.device, self.timeSteps)\n",
    "        elif self.betaMode == \"Cosine\":\n",
    "            self.betas = self._getCosineBetas(self.device, self.timeSteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bar = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_alpha_bar = torch.sqrt(self.alpha_bar)\n",
    "        self.sqrt_1_m_alpha_bar = torch.sqrt(1 - self.alpha_bar)\n",
    "\n",
    "    def forward(self, x_0, t, noise, txt=None):     # noise --> [Batch, 3, 64, 64]\n",
    "        img_pt_i = self.sqrt_alpha_bar[t].view((x_0.shape[0], 1, 1, 1)) * x_0\n",
    "        noise_pt_i = self.sqrt_1_m_alpha_bar[t].view((x_0.shape[0], 1, 1, 1)) * noise\n",
    "        x_i = img_pt_i + noise_pt_i\n",
    "        return x_i\n",
    "\n",
    "    def inverse(self, xt, et, t, txt=None):\n",
    "        xt = xt.to(self.device)\n",
    "        et = et.to(self.device)\n",
    "        epsilon_t = torch.randn_like(xt).to(self.device)\n",
    "        noise_pt_tm1 = (self.betas[t] / self.sqrt_1_m_alpha_bar[t]) * et\n",
    "        xt = (xt.to(self.device) - noise_pt_tm1.to(self.device)) / torch.sqrt(self.alphas[t]).to(self.device) + \\\n",
    "             self.betas[t].sqrt() * epsilon_t.to(self.device)\n",
    "        return xt\n",
    "\n",
    "    @staticmethod\n",
    "    def _getQuadraticBetas(device, timeSteps):\n",
    "        return torch.pow(torch.linspace(math.sqrt(0.0001), math.sqrt(0.02), timeSteps), 2).to(device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _getSigmoidBetas(device, timeSteps):\n",
    "        return torch.sigmoid(torch.linspace(-6, 6, timeSteps)).to(device) * (0.02 - 0.0001) + 0.0001\n",
    "\n",
    "    @staticmethod\n",
    "    # Reference: https://blog.csdn.net/Peach_____/article/details/128663957?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-128663957-blog-128604816.235%5Ev38%5Epc_relevant_sort_base1&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-128663957-blog-128604816.235%5Ev38%5Epc_relevant_sort_base1&utm_relevant_index=4\n",
    "    def _getCosineBetas(device, timeSteps, s=0.008):\n",
    "        steps = timeSteps + 1\n",
    "        x = torch.linspace(0, timeSteps, steps)\n",
    "        alphas_cumprod = torch.cos(((x / timeSteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        return torch.clip(betas, 0.0001, 0.9999).to(device)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.indexes = list(dataset.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indexes[index]\n",
    "        imgCombined = self.dataset[index]\n",
    "        return imgCombined\n",
    "\n",
    "\n",
    "def _inputTxtData(csvFilePath):\n",
    "    txtDataSet = {}\n",
    "    allDocs = []\n",
    "    with open(csvFilePath, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            index = int(row[0])\n",
    "            text = word_tokenize(row[1])\n",
    "            allDocs.append([text[0]] + [text[2]])\n",
    "            txtDataSet[index] = [text[0]] + [text[2]]\n",
    "    w2vModel = Word2Vec(allDocs, vector_size=2048, window=3, min_count=1, workers=1)\n",
    "    for key in txtDataSet.keys():\n",
    "        doc = txtDataSet[key]\n",
    "        newDoc = Tensor(np.array([w2vModel.wv[token] for token in doc]))\n",
    "        txtDataSet[key] = newDoc\n",
    "    return txtDataSet, w2vModel\n",
    "\n",
    "\n",
    "def _inputImgData(directoryPath) -> dict:\n",
    "    imgDataSet = {}\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    for filename in os.listdir(directoryPath):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(directoryPath, filename)\n",
    "            index = int(os.path.splitext(filename)[0])\n",
    "            image = Image.open(image_path)\n",
    "            imgDataSet[index] = transform(image)\n",
    "    return imgDataSet\n",
    "\n",
    "\n",
    "def dataLoading(batchSize, csvFilePath, directoryPath):\n",
    "    dataset = {}\n",
    "    txtDataSet, w2vModel = _inputTxtData(csvFilePath=csvFilePath)\n",
    "    imgDataSet = _inputImgData(directoryPath=directoryPath)\n",
    "\n",
    "    for key in txtDataSet.keys():\n",
    "        txtData = txtDataSet.get(key)\n",
    "        imgData = imgDataSet.get(key)\n",
    "        txtLater = txtData.view((1, 64, 64))\n",
    "        combined = torch.cat((imgData, txtLater), dim=0)\n",
    "        dataset[key] = combined\n",
    "\n",
    "    dataLoader = DataLoader(CustomDataset(dataset), batch_size=batchSize, shuffle=True)\n",
    "    return dataLoader, w2vModel\n",
    "\n",
    "\n",
    "def modelTraining(model, process, optimizer, criterion, device, modelOutputPath, epochs, dataLoader=None):\n",
    "    for e in trange(epochs):\n",
    "        running_loss = 0\n",
    "        for image in dataLoader:\n",
    "            if (image.size()[0] != process.batchSize):\n",
    "                continue\n",
    "            image = image.to(device)\n",
    "            t = torch.randint(0, process.timeSteps, (process.batchSize,), device=device, dtype=torch.long)\n",
    "            epsilon = torch.randn_like(image, device=device)\n",
    "            diffused_image = process.forward(x_0=image, t=t, noise=epsilon, txt=None)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            output = model(diffused_image.to(device), t.to(device))\n",
    "            loss = criterion(epsilon.to(device), output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value = loss.cpu().item()\n",
    "            running_loss += loss_value\n",
    "\n",
    "        # Save model after every epoch\n",
    "        torch.save(model.state_dict(), modelOutputPath)\n",
    "        running_loss /= len(dataLoader)\n",
    "        print(f\"Mean loss for Epoch {e + 1}: {running_loss:.4f}\\n\")\n",
    "\n",
    "\n",
    "def modelLoading(modelType, modelSize, modelInputPath, device):\n",
    "    model = modelType(*modelSize).to(device)\n",
    "    model.load_state_dict(torch.load(modelInputPath))\n",
    "    model.eval()\n",
    "\n",
    "    # model = model.to(\"cpu\")\n",
    "    # torch.save(model.state_dict(), \"autodl-fs/*/AnimeCPU (300).pth\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def modelInferring(model, process, device, txt=None, testLoader=None, x_t=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for t in trange(process.timeSteps - 1, -1, -1):\n",
    "            time = torch.ones(process.batchSize) * t\n",
    "            epsilonPredict = model(x_t, time.to(device))  # predict noise\n",
    "            x_t = process.inverse(xt=x_t, et=epsilonPredict, t=t)\n",
    "\n",
    "    labels = [\"Generated Images\"] * 9\n",
    "    x_t = Tensor.cpu(x_t)\n",
    "\n",
    "    for i in range(9):\n",
    "        res = torch.clamp(x_t[i][:3, :, :], 0, 1).permute(1, 2, 0)\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(res, interpolation=\"none\")\n",
    "        plt.title(labels[i])\n",
    "\n",
    "        ID = random.randint(1, 9999999)\n",
    "        res = res.numpy().astype(np.float32) * 255\n",
    "        res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(f\"SUPERANIME_{ID}.png\", res)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\"\"\" Dashboard \"\"\"\n",
    "# Training Options:\n",
    "batch_size = 100  # 64\n",
    "epochs = 500  # 50\n",
    "betaMode = [\"Quadratic\", \"Sigmoid\", \"Cosine\"][0]\n",
    "\n",
    "# Process Options:\n",
    "reloadModel = False\n",
    "trainModel = True\n",
    "testModel = True\n",
    "\n",
    "# Data Options:\n",
    "txt_csvFilePath = \"extra_data/tags.csv\"\n",
    "img_directoryPath = \"extra_data/images\"\n",
    "\n",
    "# Reloading Options:\n",
    "modelInputPath = \"Attempt_3_GPU.pth\"\n",
    "modelOutputPath = \"Attempt_3_GPU.pth\"\n",
    "modelSize = (4, 4)  # (#channel, #classes)\n",
    "modelType = UNetPlus\n",
    "\n",
    "\n",
    "\"\"\" Initializing/Reloading \"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = modelLoading(modelType=modelType, modelSize=modelSize, modelInputPath=modelInputPath,\n",
    "                     device=device) if reloadModel else UNetPlus(*modelSize).to(device)\n",
    "process = DiffusionProcess(device=device, batchSize=batch_size, betaMode=betaMode)\n",
    "\n",
    "\"\"\" Input \"\"\"\n",
    "dataLoader, w2vModel = dataLoading(batchSize=process.batchSize,\n",
    "                                   csvFilePath=txt_csvFilePath,\n",
    "                                   directoryPath=img_directoryPath)\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "if trainModel:\n",
    "    # Initialize training settings of the Adam optimizer and the MSELoss criterion;\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    modelTraining(model=model,\n",
    "                  process=process,\n",
    "                  optimizer=optimizer,\n",
    "                  criterion=criterion,\n",
    "                  device=device,\n",
    "                  modelOutputPath=modelOutputPath,\n",
    "                  epochs=epochs,\n",
    "                  dataLoader=dataLoader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a335cab22a69c37",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Sampling \"\"\"\n",
    "# Test Options:\n",
    "docs = [\"yellow hair red eyes\"] * batch_size\n",
    "\n",
    "for i in range(10):\n",
    "    if testModel:\n",
    "        dataset = {}\n",
    "        idx = 0\n",
    "        for doc in docs:\n",
    "            x_t = torch.randn(3, 64, 64)\n",
    "            doc = word_tokenize(doc)\n",
    "            txt = [doc[0]] + [doc[2]]\n",
    "            txtData = Tensor(np.array([w2vModel.wv[token] for token in txt]))\n",
    "            txtLater = txtData.view((1, 64, 64))\n",
    "            combined = torch.cat((x_t, txtLater), dim=0)\n",
    "            dataset[idx] = combined\n",
    "            idx += 1\n",
    "        testDataLoader = DataLoader(CustomDataset(dataset), batch_size=batch_size, shuffle=False)\n",
    "        for img in testDataLoader:\n",
    "            modelInferring(model=model,\n",
    "                           process=process,\n",
    "                           device=device,\n",
    "                           x_t=img.to(device))\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbda420-92bb-4508-86d9-ddb5c57e580a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
